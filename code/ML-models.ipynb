{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05c5566",
   "metadata": {},
   "source": [
    "# Training and testing target-specific machine-learning models for structure-based virtual screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdbaaf",
   "metadata": {},
   "source": [
    "This Jupyter notebook helps users train and test target-specific classification-based machine-learning models for structure-based virtual screening, with or without hyperparameter tuning, using PLEC or GRID features. For regression-based models, it is necessary to import relevant libraries and packages and adjust the code and search spaces accordingly.\n",
    "\n",
    "Additional information can be found in our Nature Protocols paper: Tran-Nguyen, V. K., Junaid, M., Simeon, S. & Ballester, P. J. A practical guide to machine-learning scoring for structure-based virtual screening. Nat. Protoc. (2023)\n",
    "\n",
    "We recommend users to set up the protocol-env environment before running the code in this Jupyter notebook. This can be done using the protocol-env.yml file in our MLSF-protocol github repository: https://github.com/vktrannguyen/MLSF-protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc534f69",
   "metadata": {},
   "source": [
    "## 1. Import all necessary Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc13a0",
   "metadata": {},
   "source": [
    "The following libraries/packages/toolkits need to be installed beforehand: jupyter notebook, pandas, oddt, sklearn, xgboost, rdkit, deepchem, joblib, tqdm, glob, tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38435f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "import oddt.pandas as opd\n",
    "from oddt.pandas import ChemDataFrame\n",
    "from oddt.fingerprints import PLEC\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "from deepchem.utils import download_url, load_from_disk\n",
    "from deepchem.utils.vina_utils import prepare_inputs\n",
    "from deepchem.models import AtomicConvModel\n",
    "from deepchem.feat import RdkitGridFeaturizer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop\n",
    "import hyperopt\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8a785",
   "metadata": {},
   "source": [
    "## 2. Load data tables for the training set and the test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b85465",
   "metadata": {},
   "source": [
    "Each data table (in the csv file format) needs to consist of at least three columns: \n",
    "- \"mol_name\": provide the identifier (IDs) of each molecule\n",
    "- \"activity\": state whether each molecule is an \"Active\" or an \"Inactive\"\n",
    "- \"potency\": provide the potency value (if available) of each molecule: pIC50, pEC50, pKd, or pKi (all active concentrations in mol/l before logarithmic conversion)\n",
    "\n",
    "Examples of these csv data files are provided in our MLSF-protocol github repository: https://github.com/vktrannguyen/MLSF-protocol. Please refer to our Nature Protocols paper cited above for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the csv training data file:\n",
    "train_data = pd.read_csv(\"pathway_to_training-set_csv_data_file\")\n",
    "\n",
    "#Provide the pathway to the csv test data file:\n",
    "test_data = pd.read_csv(\"pathway_to_test-set_csv_data_file\")\n",
    "\n",
    "#Call the \"activity\" labels of all training and test molecules:\n",
    "Train_Class = train_data['activity']\n",
    "Test_Class = test_data['activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f57fd2",
   "metadata": {},
   "source": [
    "## 3. Train and test target-specific machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df4ad3",
   "metadata": {},
   "source": [
    "Examples given in this notebook involve:\n",
    "\n",
    "- Two featurization schemes: protein-ligand extended connectivity (PLEC) fingerprints, GRID features\n",
    "- Five machine-learning algorithms: random forest (RF), extreme gradient boosting (XGB), support vector machine (SVM), artificial neural network (ANN), and deep neural network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81c357",
   "metadata": {},
   "source": [
    "### 3.1. Featurization scheme 1: PLEC fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5fa3e",
   "metadata": {},
   "source": [
    "#### 3.1.1. Import training and test molecules along with target structure(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b69287",
   "metadata": {},
   "source": [
    "- The structures of all docked molecules are in the mol2 (multi-mol2) file format.\n",
    "- The target structure(s) is (are) in the mol2 file format. The target structure for training may be different from that for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the training molecules (mol2 or multi-mol2):\n",
    "train_mol2 = opd.read_mol2(\"pathway_to_training-set_mol2_file_after_docking\")\n",
    "train_mol2.columns = ['mol', 'mol_name']\n",
    "train = train_mol2.merge(train_data.drop_duplicates(subset = ['mol_name']), how = 'left', on = 'mol_name')\n",
    "\n",
    "#Provide the pathway to the test molecules (mol2 or multi-mol2):\n",
    "test_mol2 = opd.read_mol2(\"pathway_to_test-set_mol2_file_after_docking\")\n",
    "test_mol2.columns = ['mol', 'mol_name']\n",
    "test = test_mol2.merge(test_data.drop_duplicates(subset = ['mol_name']), how = 'left', on = 'mol_name')\n",
    "\n",
    "#Extract the structures of all training and test molecules:\n",
    "train_mols = train['mol']\n",
    "test_mols = test['mol']\n",
    "\n",
    "#Provide the pathway(s) to the training and set target/receptor structure(s):\n",
    "receptor_train = next(oddt.toolkit.readfile('mol2', 'pathway_to_receptor_mol2_structure_for_training'))\n",
    "receptor_test = next(oddt.toolkit.readfile('mol2', 'pathway_to_receptor_mol2_structure_for_testing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429b980",
   "metadata": {},
   "source": [
    "#### 3.1.2. Extract PLEC fingerprints from input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12617bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Users may keep only one of the following two functions if the training target/receptor structure is the same as the test target/receptor structure\n",
    "#Users may change the parameters (size, depth_protein, depth_ligand, distance_cutoff) if they wish\n",
    "def parallel_plec_train(mol):\n",
    "    feature = PLEC(mol, protein = receptor_train, size = 4092, \n",
    "                  depth_protein = 5, depth_ligand = 1,\n",
    "                  distance_cutoff = 4.5, sparse = False)\n",
    "    return feature\n",
    "\n",
    "def parallel_plec_test(mol):\n",
    "    feature = PLEC(mol, protein = receptor_test, size = 4092, \n",
    "                  depth_protein = 5, depth_ligand = 1,\n",
    "                  distance_cutoff = 4.5, sparse = False)\n",
    "    return feature\n",
    "\n",
    "#Users may choose another number of cores (num_cores) that corresponds to their computing resources\n",
    "num_cores = 20\n",
    "train_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(parallel_plec_train)(mol) for mol in tqdm(train_mols))\n",
    "test_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(parallel_plec_test)(mol) for mol in tqdm(test_mols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa18ea7",
   "metadata": {},
   "source": [
    "#### 3.1.3. Train and test the RF algorithm\n",
    "3.1.3.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules:\n",
    "rf_plec = RandomForestClassifier(n_estimators = 400, max_features = 'sqrt', n_jobs = 30)\n",
    "rf_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(test_features)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_plec_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "plec_result_rf.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9145e",
   "metadata": {},
   "source": [
    "3.1.3.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00642a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"n_estimators\": hp.uniform(\"n_estimators\", 100, 10000),\n",
    "         \"max_depth\": hp.choice(\"max_depth\", [1, 2, 3, 4, 5, None]),\n",
    "         \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_randomforest(space):\n",
    "    model = RandomForestClassifier(n_estimators = int(space['n_estimators']),\n",
    "                                   max_depth = space['max_depth'],\n",
    "                                   criterion = space['criterion'], n_jobs = 40)\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_rf_classification = fmin(fn = hyperparameter_tuning_randomforest, space = space, algo = tpe.suggest,\n",
    "                              max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_rf_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules, using optimal parameters:\n",
    "rf_plec = RandomForestClassifier(n_estimators = int(best_params['n_estimators']), \n",
    "                                 max_depth = best_params['max_depth'], \n",
    "                                 criterion = best_params['criterion'],\n",
    "                                 max_features = 'sqrt', n_jobs = 30)\n",
    "rf_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(test_features)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_plec_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "plec_result_rf.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba96b0",
   "metadata": {},
   "source": [
    "#### 3.1.4. Train and test the XGB algorithm\n",
    "3.1.4.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGB model on the training molecules:\n",
    "xgb_plec = XGBClassifier(n_estimators = 1000, n_jobs = 40)\n",
    "xgb_plec.fit(np.array(train_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(test_features))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(test_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_xgb = pd.DataFrame({\"Active_Prob\": prediction_test_xgb_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_xgb.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda082a4",
   "metadata": {},
   "source": [
    "3.1.4.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"max_depth\": hp.uniform(\"max_depth\", 3, 18),\n",
    "         \"gamma\": hp.uniform(\"gamma\", 1, 9),\n",
    "         \"reg_alpha\": hp.uniform(\"reg_alpha\", 40, 180),\n",
    "         \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1), \n",
    "         \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "         \"min_child_weight\": hp.uniform(\"min_child_weight\", 0, 10),\n",
    "         \"n_estimators\": hp.uniform(\"n_estimators\", 1000, 5000)} \n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_XGB(space):\n",
    "    model = XGBClassifier(objective = \"binary:logistic\", \n",
    "                          max_depth = int(space['max_depth']),\n",
    "                          gamma = int(space[\"gamma\"]),\n",
    "                          reg_alpha = int(space[\"reg_alpha\"]),\n",
    "                          reg_lambda = space['reg_lambda'],\n",
    "                          colsample_bytree = space[\"colsample_bytree\"],\n",
    "                          min_child_weight = int(space[\"min_child_weight\"]),\n",
    "                          n_estimators = int(space['n_estimators']))\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_xgb_classification = fmin(fn = hyperparameter_tuning_XGB, space = space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_xgb_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cdd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGB model on the training molecules, using optimal parameters:\n",
    "xgb_plec = XGBClassifier(objective = \"binary:logistic\",\n",
    "                         max_depth = int(best_params['max_depth']),\n",
    "                         gamma = int(best_params['gamma']),\n",
    "                         reg_alpha = int(best_params['reg_alpha']),\n",
    "                         reg_lambda = best_params['reg_lambda'],\n",
    "                         colsample_bytree = best_params['colsample_bytree'],\n",
    "                         min_child_weight = int(best_params['min_child_weight']),\n",
    "                         n_estimators = int(best_params['n_estimators']),\n",
    "                         n_jobs = 40, random_state = 0)\n",
    "xgb_plec.fit(np.array(train_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(test_features))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(test_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_xgb = pd.DataFrame({\"Active_Prob\": prediction_test_xgb_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_xgb.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9521e",
   "metadata": {},
   "source": [
    "#### 3.1.5. Train and test the SVM algorithm\n",
    "3.1.5.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_plec = SVC(degree = 3, kernel = \"rbf\", probability = True)\n",
    "svm_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(test_features)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Active_Prob\": prediction_test_svm_plec_prob[:, 0],\n",
    "                                 \"Inactive_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "plec_result_svm.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3044eb",
   "metadata": {},
   "source": [
    "3.1.5.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"C\": hp.uniform(\"C\", 0, 20),\n",
    "         \"gamma\": hp.choice(\"gamma\", ['scale', 'auto']),\n",
    "         \"kernel\": hp.choice(\"kernel\", ['rbf', 'poly', 'sigmoid'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_SVM(space):\n",
    "    with parallel_backend(backend = \"multiprocessing\", n_jobs = 40):\n",
    "        model = SVC(C = space['C'],\n",
    "                    gamma = space['gamma'],\n",
    "                    kernel = space['kernel'])\n",
    "        model.fit(np.array(train_features), Train_Class)\n",
    "        predicted_train = model.predict(np.array(train_features))\n",
    "        mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "        \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_svm_classification = fmin(fn = hyperparameter_tuning_SVM, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_svm_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules, using optimal parameters:\n",
    "svm_plec = SVC(C = best_params['C'], gamma = best_params['gamma'], kernel = best_params['kernel'], \n",
    "               probability = True, random_state = 0)\n",
    "svm_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(test_features)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Active_Prob\": prediction_test_svm_plec_prob[:, 0],\n",
    "                                 \"Inactive_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "plec_result_svm.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f8c27",
   "metadata": {},
   "source": [
    "#### 3.1.6. Train and test the ANN algorithm\n",
    "3.1.6.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b265e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_plec = MLPClassifier(max_iter = 9000)\n",
    "ann_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(test_features)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_ann.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec22948",
   "metadata": {},
   "source": [
    "3.1.6.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d83ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"hidden_layer_sizes\": hp.uniform(\"hidden_layer_sizes\", 8, 140),\n",
    "         \"activation\": hp.choice(\"activation\", ['relu', 'tanh']),\n",
    "         \"max_iter\": hp.uniform(\"max_iter\", 1000, 10000)}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_ANN(space):\n",
    "    model = MLPClassifier(hidden_layer_sizes = int(space['hidden_layer_sizes']),\n",
    "                          activation = space['activation'],\n",
    "                          max_iter = int(space['max_iter']))\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_ann_classification = fmin(fn = hyperparameter_tuning_ANN, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_ann_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules, using optimal parameters:\n",
    "ann_plec = MLPClassifier(hidden_layer_sizes = int(best_params['hidden_layer_sizes']), \n",
    "                         activation = best_params['activation'], \n",
    "                         max_iter = int(best_params['max_iter']), \n",
    "                         random_state = 0)\n",
    "ann_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(test_features)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_ann.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67821e31",
   "metadata": {},
   "source": [
    "#### 3.1.7. Train and test the DNN algorithm\n",
    "3.1.7.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68240851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the DNN model on the training molecules:\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "tf.random.set_seed(0)\n",
    "dnn_plec = keras.Sequential([\n",
    "    layers.Dense(8192, kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0),\n",
    "    layers.Dense(4069, activation = \"relu\", kernel_regularizer = regularizers.l2(0)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(2048, activation = \"relu\"),\n",
    "    layers.Dropout(0),\n",
    "    layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "dnn_plec.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_plec.fit(np.array(train_features), y_train, epochs = 100, batch_size = 500, verbose = False)\n",
    "\n",
    "#Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_plec_prob = dnn_plec.predict(np.array(test_features))\n",
    "prediction_test_dnn_plec_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_plec_prob]\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_dnn = pd.DataFrame({\"Active_Prob\": prediction_test_dnn_plec_prob[:, 0],\n",
    "                                \"Predicted_Class\": prediction_test_dnn_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_dnn.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0ed06",
   "metadata": {},
   "source": [
    "3.1.7.2. With hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {'choice': hp.choice('num_layers',\n",
    "                            [ {'layers': 'two'},\n",
    "                              {'layers': 'three',\n",
    "                               'units4': hp.uniform('units4', 64, 8192), \n",
    "                               'dropout3': hp.uniform('dropout3', 0, 1)}\n",
    "                            ]),\n",
    "        'units1': hp.uniform('units1', 64, 8192),\n",
    "        'units2': hp.uniform('units2', 64, 8192),\n",
    "        'units3': hp.uniform('units3', 64, 8192),\n",
    "        'dropout1': hp.uniform('dropout1', 0, 1),\n",
    "        'dropout2': hp.uniform('dropout2', 0, 1),\n",
    "        'batch_size': hp.uniform('batch_size', 128, 500),\n",
    "        'nb_epochs': 100,\n",
    "        'optimizer': hp.choice('optimizer', ['Adadelta','Adam','rmsprop']),\n",
    "        'activation': 'relu'\n",
    "        }\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_DNN(space):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(abs(int(space['units1'])), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(space['dropout1']),\n",
    "        layers.Dense(abs(int(space['units2'])), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(abs(int(space['units3'])), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "        layers.Dropout(space['dropout2']),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'rmsprop', loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(np.array(train_features), y_train, epochs = 100, batch_size = int(space['batch_size']), verbose = False)\n",
    "    predict_proba = model.predict(np.array(train_features))[:, 0]\n",
    "    predicted_train = ['Active' if num >= 0.5 else \"Inactive\" for num in predict_proba]\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_dnn_classification = fmin(hyperparameter_tuning_DNN, space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_dnn_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the DNN model on the training molecules, using optimal parameters:\n",
    "tf.random.set_seed(0)\n",
    "dnn_plec = keras.Sequential([\n",
    "    layers.Dense(units = int(best_params['units1']), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(best_params['dropout1']),\n",
    "    layers.Dense(units = int(best_params['units2']), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units = int(best_params['units3']), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.Dropout(best_params['dropout2']),\n",
    "    layers.Dense(1, activation = \"sigmoid\")    \n",
    "])\n",
    "dnn_plec.compile(optimizer = best_params['optimizer'], loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_plec.fit(np.array(train_features), y_train, epochs = 100, \n",
    "             batch_size = int(best_params['batch_size']), verbose = False)\n",
    "\n",
    "#Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_plec_prob = dnn_plec.predict(np.array(test_features))\n",
    "prediction_test_dnn_plec_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_plec_prob]\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_dnn = pd.DataFrame({\"Active_Prob\": prediction_test_dnn_plec_prob[:, 0],\n",
    "                                \"Predicted_Class\": prediction_test_dnn_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_dnn.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d27f5",
   "metadata": {},
   "source": [
    "### 3.2. Featurization scheme 2: Grid features\n",
    "#### 3.2.1. Import training and test molecules along with target structure(s)\n",
    "- The structures of all docked molecules are in the sdf (multi-sdf) file format.\n",
    "- The target structure(s) is (are) in the pdb file format. The target structure for training may be different from that for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the training molecules (sdf or multi-sdf):\n",
    "train_sdf = opd.read_sdf(\"pathway_to_the_training-set_sdf_after_docking\")\n",
    "train = train_sdf.merge(train_data.drop_duplicates(subset = ['mol_name']), how = 'left', on = 'mol_name')\n",
    "\n",
    "#Split the multi-sdf training data into individual sdf structures:\n",
    "for i in range(train_sdf.shape[0]):\n",
    "    each_sdf = train_sdf.iloc[[i]]\n",
    "    each_name = list(each_sdf['mol_name'])[0]\n",
    "    out_path = '/pathway_to_the_directory_to_store_individual_training-set_sdfs/' + str(each_name) + '.sdf'\n",
    "    ChemDataFrame.to_sdf(each_sdf, out_path)\n",
    "training_set = glob.glob(\"/pathway_to_the_directory_to_store_individual_training-set_sdfs/*\")\n",
    "\n",
    "#Provide the pathway to the test molecules (sdf or multi-sdf):\n",
    "test_sdf = opd.read_sdf(\"pathway_to_the_test-set_sdf_after_docking\")\n",
    "test = test_sdf.merge(test_data.drop_duplicates(subset = ['mol_name']), how = 'left', on = 'mol_name')\n",
    "\n",
    "#Split the multi-sdf test data into individual sdf structures:\n",
    "for i in range(test_sdf.shape[0]):\n",
    "    each_sdf = test_sdf.iloc[[i]]\n",
    "    each_name = list(each_sdf['mol_name'])[0]\n",
    "    out_path = '/pathway_to_the_directory_to_store_individual_test-set_sdfs/' + str(each_name) + '.sdf'\n",
    "    ChemDataFrame.to_sdf(each_sdf, out_path)\n",
    "test_set = glob.glob(\"/pathway_to_the_directory_to_store_individual_test-set_sdfs/*\")\n",
    "\n",
    "#Extract the structures of all training and test molecules:\n",
    "train_mols = train['mol']\n",
    "test_mols = test['mol']\n",
    "\n",
    "#Provide the pathway(s) to the training and set target/receptor structure(s):\n",
    "protein_train = \"pathway_to_receptor_pdb_file_for_training\"\n",
    "protein_test = \"pathway_to_receptor_pdb_file_for_testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed354b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Users may keep only one of the following two functions if the training target/receptor structure is the same as the test target/receptor structure\n",
    "#Users may change the parameters (voxel_width, feature_types, ecfp_power, splif_power) if they wish\n",
    "featurizer = RdkitGridFeaturizer(voxel_width = 16.0, feature_types = [\"ecfp\", \"splif\", \"hbond\", \"salt_bridge\"], ecfp_power = 9, splif_power = 9, flatten = True, verbose = False)\n",
    "def extract_grid_feature_train(ligand_file):\n",
    "    try:\n",
    "        feature = featurizer._featurize((ligand_file, protein_train))\n",
    "        return feature\n",
    "    except:\n",
    "        pass\n",
    "def extract_grid_feature_test(ligand_file):\n",
    "    try:\n",
    "        feature = featurizer._featurize((ligand_file, protein_test))\n",
    "        return feature\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Users may choose another number of cores (num_cores) that corresponds to their computing resources\n",
    "num_cores = 20\n",
    "train_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(extract_grid_feature_train)(ligand_file) for ligand_file in tqdm(training_set))\n",
    "test_features = Parallel(n_jobs = num_cores, backend = \"multiprocessing\")(delayed(extract_grid_feature_test)(ligand_file) for ligand_file in tqdm(test_set))\n",
    "\n",
    "#Export grid features as npy files:\n",
    "np.save('where_you_want_to_store_the_npy_file_containing_GRID_features_of_training-set', train_features)\n",
    "np.save('where_you_want_to_store_the_npy_file_containing_GRID_features_of_test-set', test_features)\n",
    "\n",
    "#Load grid features for the next stages:\n",
    "train_grid_features = np.load(\"where_you_want_to_store_the_npy_file_containing_GRID_features_of_training-set\")\n",
    "test_grid_features = np.load(\"where_you_want_to_store_the_npy_file_containing_GRID_features_of_test-set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd22744",
   "metadata": {},
   "source": [
    "The following part is necessary for the hyperparameter tuning process only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize grid features for hyperparameter tuning:\n",
    "train_rdkit_grid_features = pd.DataFrame(train_grid_features)\n",
    "test_rdkit_grid_features = pd.DataFrame(test_grid_features)\n",
    "\n",
    "def normalize(feature):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    np_scaled = min_max_scaler.fit_transform(feature)\n",
    "    fp_normalize = pd.DataFrame(np_scaled)\n",
    "    return fp_normalize\n",
    "\n",
    "train_rdkit_grid_features = normalize(train_rdkit_grid_features)\n",
    "test_rdkit_grid_features = normalize(test_rdkit_grid_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa352a4",
   "metadata": {},
   "source": [
    "#### 3.2.3. Train and test the RF algorithm\n",
    "3.2.3.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd295a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules:\n",
    "rf_grid = RandomForestClassifier(n_estimators = 500, n_jobs = 30, random_state = 0)\n",
    "rf_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_grid_class = rf_grid.predict(test_grid_features)\n",
    "prediction_test_rf_grid_prob = rf_grid.predict_proba(test_grid_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_grid_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_grid_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_grid_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "grid_result_rf.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba8a31",
   "metadata": {},
   "source": [
    "3.2.3.2. With hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"n_estimators\": hp.uniform(\"n_estimators\", 100, 10000),\n",
    "         \"max_depth\": hp.choice(\"max_depth\", [1, 2, 3, 4, 5, None]),\n",
    "         \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_randomforest(space):\n",
    "    model = RandomForestClassifier(n_estimators = int(space['n_estimators']),\n",
    "                                   max_depth = space['max_depth'],\n",
    "                                   criterion = space['criterion'], n_jobs = 40)\n",
    "    model.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "    predicted_train = model.predict(train_rdkit_grid_features)\n",
    "    mcc = matthews_corrcoef(predicted_train, Train_Class)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_rf_classification = fmin(hyperparameter_tuning_randomforest, space, algo = tpe.suggest, \n",
    "                              max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_rf_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea95908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules, using optimal parameters:\n",
    "rf_grid = RandomForestClassifier(n_estimators = int(best_params['n_estimators']), \n",
    "                                 max_depth = best_params['max_depth'], \n",
    "                                 criterion = best_params['criterion'],\n",
    "                                 max_features = 'sqrt', n_jobs = 30, random_state = 0)\n",
    "rf_grid.fit(train_rdkit_grid_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_grid_class = rf_grid.predict(test_rdkit_grid_features)\n",
    "prediction_test_rf_grid_prob = rf_grid.predict_proba(test_rdkit_grid_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_grid_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_grid_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_grid_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "grid_result_rf.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f1a0a",
   "metadata": {},
   "source": [
    "#### 3.2.4. Train and test the XGB algorithm\n",
    "3.2.4.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074895fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGB model on the training molecules:\n",
    "xgb_grid = XGBClassifier(n_estimators = 745, max_depth = 7, learning_rate = 0.05, n_jobs = 40, random_state = 0)\n",
    "xgb_grid.fit(np.array(train_grid_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_grid_class = xgb_grid.predict(np.array(test_grid_features))\n",
    "prediction_test_xgb_grid_prob = xgb_grid.predict_proba(np.array(test_grid_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_xgb = pd.DataFrame({\"Active_Prob\": prediction_test_xgb_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_xgb_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_xgb.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541c6cc",
   "metadata": {},
   "source": [
    "3.2.4.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"max_depth\": hp.uniform(\"max_depth\", 3, 18),\n",
    "         \"gamma\": hp.uniform(\"gamma\", 1, 9),\n",
    "         \"reg_alpha\": hp.uniform(\"reg_alpha\", 40, 180),\n",
    "         \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1), \n",
    "         \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "         \"min_child_weight\": hp.uniform(\"min_child_weight\", 0, 10),\n",
    "         \"n_estimators\": hp.uniform(\"n_estimators\", 1000, 5000)} \n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_XGB(space):\n",
    "    model = XGBClassifier(objective = \"binary:logistic\", \n",
    "                          max_depth = int(space['max_depth']),\n",
    "                          gamma = int(space[\"gamma\"]),\n",
    "                          reg_alpha = int(space[\"reg_alpha\"]),\n",
    "                          reg_lambda = space['reg_lambda'],\n",
    "                          colsample_bytree = space[\"colsample_bytree\"],\n",
    "                          min_child_weight = int(space[\"min_child_weight\"]),\n",
    "                          n_estimators = int(space['n_estimators']))\n",
    "    model.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_rdkit_grid_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_xgb_classification = fmin(fn = hyperparameter_tuning_XGB, space = space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_xgb_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGB model on the training molecules, using optimal parameters:\n",
    "xgb_grid = XGBClassifier(objective = \"binary:logistic\",\n",
    "                         max_depth = int(best_params['max_depth']),\n",
    "                         gamma = int(best_params['gamma']),\n",
    "                         reg_alpha = int(best_params['reg_alpha']),\n",
    "                         reg_lambda = best_params['reg_lambda'],\n",
    "                         colsample_bytree = best_params['colsample_bytree'],\n",
    "                         min_child_weight = int(best_params['min_child_weight']),\n",
    "                         n_estimators = int(best_params['n_estimators']),\n",
    "                         n_jobs = 40, random_state = 0)\n",
    "xgb_grid.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_grid_class = xgb_grid.predict(np.array(test_rdkit_grid_features))\n",
    "prediction_test_xgb_grid_prob = xgb_grid.predict_proba(np.array(test_rdkit_grid_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_xgb = pd.DataFrame({\"Active_Prob\": prediction_test_xgb_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_xgb_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_xgb.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9055ba6",
   "metadata": {},
   "source": [
    "#### 3.2.5. Train and test the SVM algorithm\n",
    "3.2.5.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_grid = SVC(degree = 3, kernel = \"rbf\", probability = True, random_state = 0)\n",
    "svm_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_grid_class = svm_grid.predict(test_grid_features)\n",
    "prediction_test_svm_grid_prob = svm_grid.predict_proba(test_grid_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_svm = pd.DataFrame({\"Active_Prob\": prediction_test_svm_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_svm_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_svm_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_svm.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83191e3",
   "metadata": {},
   "source": [
    "3.2.5.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"C\": hp.uniform(\"C\", 1, 20),\n",
    "         \"gamma\": hp.choice(\"gamma\", ['scale', 'auto']),\n",
    "         \"kernel\": hp.choice(\"kernel\", ['rbf', 'poly', 'sigmoid'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_SVM(space):\n",
    "    with parallel_backend(backend = \"multiprocessing\", n_jobs = 40):\n",
    "        model = SVC(C = space['C'],\n",
    "                    gamma = space['gamma'],\n",
    "                    kernel = space['kernel'], probability = True)\n",
    "        model.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "        predicted_train = model.predict(np.array(train_rdkit_grid_features))\n",
    "        mcc = matthews_corrcoef(predicted_train, Train_Class)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, \"model\": model}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_svm_classification = fmin(fn = hyperparameter_tuning_SVM, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_svm_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules, using optimal parameters:\n",
    "svm_grid = SVC(C = best_params['C'], gamma = best_params['gamma'], kernel = best_params['kernel'], \n",
    "               probability = True, random_state = 0)\n",
    "svm_grid.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_grid_class = svm_grid.predict(test_rdkit_grid_features)\n",
    "prediction_test_svm_grid_prob = svm_grid.predict_proba(test_rdkit_grid_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_svm = pd.DataFrame({\"Active_Prob\": prediction_test_svm_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_svm_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_svm_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_svm.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fac3b1",
   "metadata": {},
   "source": [
    "#### 3.2.6. Train and test the ANN algorithm\n",
    "3.2.6.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75762f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_grid = MLPClassifier(max_iter = 500, random_state = 0)\n",
    "ann_grid.fit(train_grid_features, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_grid_class = ann_grid.predict(test_grid_features)\n",
    "prediction_test_ann_grid_prob = ann_grid.predict_proba(test_grid_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_ann.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26852b6c",
   "metadata": {},
   "source": [
    "3.2.6.2. With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"hidden_layer_sizes\": hp.uniform(\"hidden_layer_sizes\", 8, 140),\n",
    "         \"activation\": hp.choice(\"activation\", ['relu', 'tanh']),\n",
    "         \"max_iter\": hp.uniform(\"max_iter\", 1000, 10000)}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_ANN(space):\n",
    "    model = MLPClassifier(hidden_layer_sizes = int(space['hidden_layer_sizes']),\n",
    "                          activation = space['activation'],\n",
    "                          max_iter = int(space['max_iter']))\n",
    "    model.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_rdkit_grid_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {\"loss\": 1-mcc, \"status\": STATUS_OK, 'model': model}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_ann_classiifcation = fmin(fn = hyperparameter_tuning_ANN, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_ann_classiifcation)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bcb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules, using optimal parameters:\n",
    "ann_grid = MLPClassifier(hidden_layer_sizes = int(best_params['hidden_layer_sizes']), \n",
    "                         activation = best_params['activation'], \n",
    "                         max_iter = int(best_params['max_iter']), \n",
    "                         random_state = 0)\n",
    "ann_grid.fit(np.array(train_rdkit_grid_features), Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_grid_class = ann_grid.predict(np.array(test_rdkit_grid_features))\n",
    "prediction_test_ann_grid_prob = ann_grid.predict_proba(np.array(test_rdkit_grid_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_grid_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_grid_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_ann.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13587bab",
   "metadata": {},
   "source": [
    "#### 3.2.7. Train and test the DNN algorithm\n",
    "3.2.7.1. Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49540b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the DNN model on the training molecules:\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "tf.random.set_seed(0)\n",
    "dnn_grid = keras.Sequential([\n",
    "    layers.Dense(8192, kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0),\n",
    "    layers.Dense(4069, activation = \"relu\", kernel_regularizer = regularizers.l2(0)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(2048, activation = \"relu\"),\n",
    "    layers.Dropout(0),\n",
    "    layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "dnn_grid.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_grid.fit(train_grid_features, y_train, epochs = 100, batch_size = 500, verbose = False)\n",
    "\n",
    "#Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_grid_prob = dnn_grid.predict(test_grid_features)\n",
    "prediction_test_dnn_grid_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_grid_prob]\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_dnn = pd.DataFrame({\"Active_Prob\": prediction_test_dnn_grid_prob[:, 0],\n",
    "                                \"Predicted_Class\": prediction_test_dnn_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_dnn.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {'choice': hp.choice('num_layers',\n",
    "                            [ {'layers': 'two'},\n",
    "                              {'layers': 'three',\n",
    "                               'units4': hp.uniform('units4', 64, 8192), \n",
    "                               'dropout3': hp.uniform('dropout3', 0, 1)}\n",
    "                            ]),\n",
    "        'units1': hp.uniform('units1', 64, 8192),\n",
    "        'units2': hp.uniform('units2', 64, 8192),\n",
    "        'units3': hp.uniform('units3', 64, 8192),\n",
    "        'dropout1': hp.uniform('dropout1', 0, 1),\n",
    "        'dropout2': hp.uniform('dropout2', 0, 1),\n",
    "        'batch_size': hp.uniform('batch_size', 128, 500),\n",
    "        'nb_epochs': 100,\n",
    "        'optimizer': hp.choice('optimizer', ['Adadelta','Adam','rmsprop']),\n",
    "        'activation': 'relu'\n",
    "        }\n",
    "Activity_Dict = {\"Active\": 1, \"Inactive\": 0}\n",
    "y_train = [Activity_Dict[item] for item in Train_Class]\n",
    "y_test = [Activity_Dict[item] for item in Test_Class]\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_DNN(space):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(abs(int(space['units1'])), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(space['dropout1']),\n",
    "        layers.Dense(abs(int(space['units2'])), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(abs(int(space['units3'])), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "        layers.Dropout(space['dropout2']),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = 'rmsprop', loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(np.array(train_rdkit_grid_features), y_train, epochs = 100, batch_size = int(space['batch_size']), \n",
    "              verbose = False)\n",
    "    prediction_train_prob_dnn_grid = model.predict(np.array(train_rdkit_grid_features))[:, 0]\n",
    "    prediction_train_class_dnn_grid = np.where(prediction_train_prob_dnn_grid >= 0.5, \"Active\", \"Inactive\")\n",
    "    mcc = matthews_corrcoef(Train_Class, prediction_train_class_dnn_grid)\n",
    "    return {'loss': 1-mcc, \"status\": STATUS_OK, 'model': model}\n",
    "\n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_dnn_classification = fmin(fn = hyperparameter_tuning_DNN, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_dnn_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the DNN model on the training molecules, using optimal parameters:\n",
    "tf.random.set_seed(0)\n",
    "dnn_grid = keras.Sequential([\n",
    "    layers.Dense(units = int(best_params['units1']), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(best_params['dropout1']),\n",
    "    layers.Dense(units = int(best_params['units2']), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units = int(best_params['units3']), kernel_regularizer = regularizers.l2(0), activation = \"relu\"),\n",
    "    layers.Dropout(best_params['dropout2']),\n",
    "    layers.Dense(1, activation = \"sigmoid\")    \n",
    "])\n",
    "dnn_grid.compile(optimizer = best_params['optimizer'], loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "dnn_grid.fit(np.array(train_rdkit_grid_features), y_train, epochs = 100, \n",
    "             batch_size = int(best_params['batch_size']), verbose = False)\n",
    "\n",
    "#Test the DNN model on the test molecules:\n",
    "prediction_test_dnn_grid_prob = dnn_grid.predict(np.array(test_rdkit_grid_features))\n",
    "prediction_test_dnn_grid_class = ['Active' if num >= 0.5 else \"Inactive\" for num in prediction_test_dnn_plec_prob]\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "grid_result_dnn = pd.DataFrame({\"Active_Prob\": prediction_test_dnn_grid_prob[:, 0],\n",
    "                                \"Predicted_Class\": prediction_test_dnn_grid_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "grid_result_dnn.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
